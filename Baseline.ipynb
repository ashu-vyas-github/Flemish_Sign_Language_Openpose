{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRED IMPORTS FROM STANDARD PACKAGES\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from os.path import join as pjoin\n",
    "from glob import glob\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# IMPORTS FROM THE UTIL LIBRARY PROVIDED BY US\n",
    "\n",
    "import util.vis as V\n",
    "import util.helpers as H\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport util.helpers, util.vis\n",
    "rng = np.random.RandomState(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "POSE_DIR = '../data/pose'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 0. To obtain reproducible results, we set the random seeds\n",
    "random.seed(2019)\n",
    "np.random.seed(2019)\n",
    "\n",
    "## 1. Load training set\n",
    "\n",
    "dataset_file = pjoin(DATA_DIR, 'labels.csv')\n",
    "\n",
    "train_samples = []\n",
    "train_labels = []\n",
    "\n",
    "with open(dataset_file) as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader) # Skips the first row, which is the header\n",
    "    for row in reader:\n",
    "        name, _gloss, label, _person = row\n",
    "        sample = np.load(pjoin(POSE_DIR, 'train', name + '.npy'))\n",
    "        train_samples.append(sample)\n",
    "        train_labels.append(int(label))\n",
    "\n",
    "## 2. Load test set.\n",
    "# Important: load according to the order in files_test.txt to ensure correct submissions on Kaggle!\n",
    "# The code below does this for you.\n",
    "test_samples_file = pjoin(DATA_DIR, 'files_test.txt')\n",
    "\n",
    "test_samples = []\n",
    "\n",
    "with open(test_samples_file) as test_file:\n",
    "    test_file_names = [l.strip() for l in test_file.readlines()]\n",
    "    for name in test_file_names:\n",
    "        test_samples.append(np.load(pjoin(POSE_DIR, 'test', name + '.npy')))\n",
    "    \n",
    "## 3. Extract features you will use in your model\n",
    "#     (just a very basic dummy here!!!)\n",
    "#     Transform the training set and test set to a numpy array\n",
    "\n",
    "# As very basic features, we will use the average values of x, y and c \n",
    "# for every keypoint array over time,\n",
    "# resulting in 3*137=411 features per sample\n",
    "def extract_features(samples_list):\n",
    "    # Calculate the average over time\n",
    "    l = [np.mean(sample, axis=0) for sample in samples_list] \n",
    "    # Create a numpy array\n",
    "    X = np.stack(l, axis=0)  \n",
    "    # Reshape to (n_samples, n_features)\n",
    "    X = X.reshape((len(samples_list), -1))                    \n",
    "    return X\n",
    "\n",
    "X_train = extract_features(train_samples)\n",
    "y_train = np.array(train_labels)\n",
    "X_test = extract_features(test_samples)\n",
    "\n",
    "## 4. Create a classifier and fit the training set\n",
    "## Note that this is JUST AN EXAMPLE \n",
    "#  in which logistic regression is used with the default settings!!\n",
    "clf = LogisticRegression(max_iter=500000)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the accuracy obtained on the training set\n",
    "print('Training set accuracy:', clf.score(X_train, y_train))\n",
    "train_probas = clf.predict_proba(X_train)\n",
    "print('Training set score (map@3):', H.mapk(train_probas, y_train))\n",
    "print('Training set top-3 accuracy:', H.top3_accuracy(train_probas, y_train))\n",
    "\n",
    "# 5. Create a submission using the test set data and write the submission file using the provided code\n",
    "test_probas = clf.predict_proba(X_test)\n",
    "H.create_submission(test_probas, 'baseline_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submission should give you a leaderboard map@3 score of 0.5822, which shows that the model is clearly overfitting!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
